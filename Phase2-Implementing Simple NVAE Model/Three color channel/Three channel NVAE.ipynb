{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjDLqu_YrqUS"
      },
      "source": [
        "# Dataset download and save in drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWrguuyjqtEc",
        "outputId": "aa1293c0-a8ce-48e5-d027-3adaa44d90fe"
      },
      "outputs": [],
      "source": [
        "!wget http://images.cocodataset.org/zips/val2014.zip --verbose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR4hxNpGr9qn",
        "outputId": "b238fc23-8ba8-456f-bb76-354907d52a79"
      },
      "outputs": [],
      "source": [
        "!unzip val2014.zip -d /content/CocoVal2014"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6yDJamlit02j"
      },
      "outputs": [],
      "source": [
        "!rm /content/val2014.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2K3A0-ZwoRa"
      },
      "source": [
        "# Dataset prepratation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "fhWqcbHbxBXD"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = '/content/CocoVal2014'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0J4fMH7g1WpB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "FINAL_PATH = '/content/CocoVal2014-modified'\n",
        "\n",
        "if not os.path.exists(FINAL_PATH):\n",
        "  os.makedirs(FINAL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "qF2HTurYrqfL"
      },
      "outputs": [],
      "source": [
        "from PIL import Image,ImageChops\n",
        "\n",
        "def is_greyscale(im):\n",
        "    if im.mode not in (\"L\", \"RGB\"):\n",
        "        raise ValueError(\"Unsuported image mode\")\n",
        "\n",
        "    if im.mode == \"RGB\":\n",
        "        rgb = im.split()\n",
        "        if ImageChops.difference(rgb[0],rgb[1]).getextrema()[1]!=0: \n",
        "            return False\n",
        "        if ImageChops.difference(rgb[0],rgb[2]).getextrema()[1]!=0: \n",
        "            return False\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfovdDFKzvdK",
        "outputId": "716b2559-4066-491a-e314-14fc56de37d2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "for subdir, dirs, files in os.walk(DATASET_PATH):\n",
        "    for file in tqdm(files):\n",
        "        filepath = subdir + os.sep + file\n",
        "        image = Image.open(filepath)\n",
        "\n",
        "        if is_greyscale(image):\n",
        "          continue\n",
        "\n",
        "        new_image = image.resize((64, 64))\n",
        "        new_image.save(FINAL_PATH + os.sep + file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "l3U8Znc-iVj0"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/CocoVal2014/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fss06xstGrQd"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pwpSvaz0d7xk"
      },
      "outputs": [],
      "source": [
        "FINAL_PATH = '/content/CocoVal2014-modified'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPPudYNi2Dpl",
        "outputId": "a3689a5e-a825-4057-f49d-378d34ef353b"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "OKJbU0EBMCjX"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL3MZKX1R8Ag",
        "outputId": "34213202-fe6e-4b7c-dc14-3efd26369788"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "kayWTvW9SBjE"
      },
      "outputs": [],
      "source": [
        "class depthwise_separable_conv(nn.Module):\n",
        "    def __init__(self, nin, kernels_per_layer, nout):\n",
        "        super(depthwise_separable_conv, self).__init__()\n",
        "        self.depthwise = nn.Conv2d(nin, nin * kernels_per_layer, kernel_size=5, padding=2, groups=nin)\n",
        "        self.pointwise = nn.Conv2d(nin * kernels_per_layer, nout, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.depthwise(x)\n",
        "        out = self.pointwise(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "VGe2_v2OSFuU"
      },
      "outputs": [],
      "source": [
        "def swish(x):\n",
        "    return x * torch.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "TLz01lmuSHWm"
      },
      "outputs": [],
      "source": [
        "class ChannelSELayer(nn.Module):\n",
        "    def __init__(self, num_channels, reduction_ratio=2):\n",
        "        super(ChannelSELayer, self).__init__()\n",
        "        num_channels_reduced = num_channels // reduction_ratio\n",
        "        self.reduction_ratio = reduction_ratio\n",
        "        self.fc1 = nn.Linear(num_channels, num_channels_reduced, bias=True)\n",
        "        self.fc2 = nn.Linear(num_channels_reduced, num_channels, bias=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        batch_size, num_channels, H, W = input_tensor.size()\n",
        "        squeeze_tensor = input_tensor.view(batch_size, num_channels, -1).mean(dim=2)\n",
        "\n",
        "        fc_out_1 = self.relu(self.fc1(squeeze_tensor))\n",
        "        fc_out_2 = self.sigmoid(self.fc2(fc_out_1))\n",
        "\n",
        "        a, b = squeeze_tensor.size()\n",
        "        output_tensor = torch.mul(input_tensor, fc_out_2.view(a, b, 1, 1))\n",
        "        return output_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "zuJiuDzESKBS"
      },
      "outputs": [],
      "source": [
        "class dec_res(nn.Module):\n",
        "  def __init__(self,in_channel):\n",
        "    super(dec_res,self).__init__()\n",
        "    \n",
        "    self.bn1 = nn.BatchNorm2d(in_channel)\n",
        "    \n",
        "    self.c1 = nn.Conv2d(in_channels=in_channel,out_channels=2*in_channel,kernel_size=1,stride=1,padding=0)\n",
        "    self.bn2 = nn.BatchNorm2d(2*in_channel)\n",
        "\n",
        "    self.c2 = nn.Conv2d(in_channels=2*in_channel,out_channels=4*in_channel,kernel_size=1,stride=1,padding=0)\n",
        "    self.bn3 = nn.BatchNorm2d(4*in_channel)\n",
        "\n",
        "    self.c3 = nn.Conv2d(in_channels=4*in_channel,out_channels=8*in_channel,kernel_size=1,stride=1,padding=0)\n",
        "    self.bn4 = nn.BatchNorm2d(8*in_channel)\n",
        "\n",
        "    self.dc1 = depthwise_separable_conv(nin=8*in_channel,kernels_per_layer=3,nout=8*in_channel)\n",
        "\n",
        "    self.bn5 = nn.BatchNorm2d(8*in_channel)\n",
        "    self.c4 = nn.Conv2d(in_channels=8*in_channel,out_channels=4*in_channel,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "    self.bn6 = nn.BatchNorm2d(4*in_channel)\n",
        "    self.c5 = nn.Conv2d(in_channels=4*in_channel,out_channels=2*in_channel,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "    self.bn7 = nn.BatchNorm2d(2*in_channel)\n",
        "    self.c6 = nn.Conv2d(in_channels=2*in_channel,out_channels=in_channel,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "    self.bn8 = nn.BatchNorm2d(in_channel)\n",
        "\n",
        "    self.SE = ChannelSELayer(in_channel)\n",
        "\n",
        "  def forward(self,x1):\n",
        "    x = self.c1(self.bn1(x1))\n",
        "    \n",
        "    x = swish(self.bn2(x))\n",
        "    x = self.c2(x)\n",
        "    \n",
        "    x = swish(self.bn3(x))\n",
        "    x = self.c3(x)\n",
        "\n",
        "    x = swish(self.bn4(x))\n",
        "    x = self.dc1(x)\n",
        "\n",
        "    x = swish(self.bn5(x))\n",
        "    x = self.c4(x)\n",
        "\n",
        "    x = swish(self.bn6(x))\n",
        "    x = self.c5(x)\n",
        "\n",
        "    x = swish(self.bn7(x))\n",
        "    x = self.c6(x)\n",
        "    \n",
        "    x = self.bn8(x)\n",
        "    x = self.SE(x)\n",
        "    return x+x1\n",
        "\n",
        "class enc_res(nn.Module):\n",
        "  def __init__(self,in_channel):\n",
        "    super(enc_res,self).__init__()\n",
        "\n",
        "    self.bn1 = nn.BatchNorm2d(in_channel)\n",
        "\n",
        "    self.c1 = nn.Conv2d(in_channels=in_channel,out_channels=2*in_channel,kernel_size=3,stride=1,padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(2*in_channel)\n",
        "\n",
        "    self.c2 = nn.Conv2d(in_channels=2*in_channel,out_channels=4*in_channel,kernel_size=3,stride=1,padding=1)\n",
        "    self.bn3 = nn.BatchNorm2d(4*in_channel)\n",
        "\n",
        "    self.c3 = nn.Conv2d(in_channels=4*in_channel,out_channels=8*in_channel,kernel_size=3,stride=1,padding=1)\n",
        "    self.bn4 = nn.BatchNorm2d(8*in_channel)\n",
        "\n",
        "    self.c4 = nn.Conv2d(in_channels=8*in_channel,out_channels=4*in_channel,kernel_size=3,stride=1,padding=1)\n",
        "    self.bn5 = nn.BatchNorm2d(4*in_channel)\n",
        "\n",
        "    self.c5 = nn.Conv2d(in_channels=4*in_channel,out_channels=2*in_channel,kernel_size=3,stride=1,padding=1)\n",
        "    self.bn6 = nn.BatchNorm2d(2*in_channel)\n",
        "\n",
        "    self.c6 = nn.Conv2d(in_channels=2*in_channel,out_channels=in_channel,kernel_size=3,stride=1,padding=1)\n",
        "    self.bn7 = nn.BatchNorm2d(in_channel)\n",
        "\n",
        "    self.SE = ChannelSELayer(in_channel)\n",
        "  def forward(self,x1):\n",
        "    x = swish(self.bn1(x1))\n",
        "    x = self.c1(x)\n",
        "\n",
        "    x = swish(self.bn2(x))\n",
        "    x = self.c2(x)\n",
        "\n",
        "    x = swish(self.bn3(x))\n",
        "    x = self.c3(x)\n",
        "\n",
        "    x = swish(self.bn4(x))\n",
        "    x = self.c4(x)\n",
        "\n",
        "    x = swish(self.bn5(x))\n",
        "    x = self.c5(x)\n",
        "\n",
        "    x = swish(self.bn6(x))\n",
        "    x = self.c6(x)\n",
        "\n",
        "    x = swish(self.bn7(x))\n",
        "    x = self.SE(x)\n",
        "    return x+x1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "tb23V7iiSOnU"
      },
      "outputs": [],
      "source": [
        "class NVAE(nn.Module):\n",
        "  def __init__(self,start_channel,original_dim):\n",
        "    super(NVAE,self).__init__()\n",
        "    self.original_dim = original_dim\n",
        "    self.conv1 = nn.Conv2d(in_channels=start_channel,out_channels=8,kernel_size=3,stride=1,padding=1)\n",
        "    self.encblock1 = enc_res(8)\n",
        "    self.dsconv1 = nn.Conv2d(in_channels=8,out_channels=8,kernel_size=2,stride=2,padding=0)\n",
        "    self.encblock2 = enc_res(8)\n",
        "    self.dsconv2 = nn.Conv2d(in_channels=8,out_channels=8,kernel_size=2,stride=2,padding=0)\n",
        "\n",
        "    self.qmu1 = nn.Linear(original_dim*original_dim*2,original_dim*original_dim*2)\n",
        "    self.qvar1 = nn.Linear(original_dim*original_dim*2,original_dim*original_dim*2)\n",
        "    \n",
        "    self.qmu0 = nn.Linear(original_dim*original_dim//2,original_dim*original_dim//2)\n",
        "    self.qvar0 = nn.Linear(original_dim*original_dim//2,original_dim*original_dim//2)\n",
        "\n",
        "    self.pmu1 = nn.Linear(original_dim*original_dim*2,original_dim*original_dim*2)\n",
        "    self.pvar1 = nn.Linear(original_dim*original_dim*2,original_dim*original_dim*2)\n",
        "\n",
        "    self.decblock1 = dec_res(8)\n",
        "    self.usconv1 = nn.ConvTranspose2d(in_channels=8,out_channels=8,kernel_size=2,stride=2,padding=0)\n",
        "    self.decblock2 = dec_res(16)\n",
        "    self.usconv2 = nn.ConvTranspose2d(in_channels=16,out_channels=16,kernel_size=2,stride=2,padding=0)\n",
        "    self.decblock3 = dec_res(16)\n",
        "    self.finconv = nn.Conv2d(in_channels=16,out_channels=start_channel,kernel_size=3,stride=1,padding=1)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    z1 = self.dsconv1(self.encblock1(self.conv1(x)))\n",
        "    z0 = self.dsconv2(self.encblock2(z1))\n",
        "\n",
        "    qmu0 = self.qmu0(z0.reshape(z0.shape[0],self.original_dim*self.original_dim//2))\n",
        "    qvar0 = self.qvar0(z0.reshape(z0.shape[0],self.original_dim*self.original_dim//2))\n",
        "\n",
        "    qmu1 = self.qmu1(z1.reshape(z1.shape[0],self.original_dim*self.original_dim*2))\n",
        "    qvar1 = self.qvar1(z1.reshape(z1.shape[0],self.original_dim*self.original_dim*2))\n",
        "\n",
        "    stdvar0 = qvar0.mul(0.5).exp_()\n",
        "    stdvar1 = qvar1.mul(0.5).exp_()\n",
        "\n",
        "    e0 = torch.randn(qmu0.shape).to(device)\n",
        "    ez0 = qmu0+e0*stdvar0\n",
        "    ez0 = ez0.reshape(ez0.shape[0],8,self.original_dim//4,self.original_dim//4)\n",
        "    ez1 = self.usconv1(self.decblock1(ez0))\n",
        "\n",
        "    pmu1 = self.pmu1(ez1.reshape(ez1.shape[0],self.original_dim*self.original_dim*2))\n",
        "    pvar1 = self.pvar1(ez1.reshape(ez1.shape[0],self.original_dim*self.original_dim*2))\n",
        "\n",
        "    pstdvar1 = pvar1.mul(0.5).exp_()\n",
        "\n",
        "    e2 = torch.randn(qmu1.shape).to(device)\n",
        "    ez2 = pmu1+qmu1 + e2*pstdvar1*stdvar1\n",
        "    ez2 = ez2.reshape(ez2.shape[0],8,self.original_dim//2,self.original_dim//2)\n",
        "    \n",
        "    final = torch.cat((ez1,ez2),1)\n",
        "\n",
        "    recons = nn.Sigmoid()(self.finconv(self.decblock3(self.usconv2(self.decblock2(final)))))\n",
        "\n",
        "    return qmu0,qvar0,qmu1,qvar1,pmu1,pvar1,recons\n",
        "\n",
        "  def sample(self,bs):\n",
        "    e = torch.randn([bs,8,self.original_dim//4,self.original_dim//4]).to(device)\n",
        "    ez1 = self.usconv1(self.decblock1(e))\n",
        "\n",
        "    pmu1 = self.pmu1(ez1.reshape(ez1.shape[0],self.original_dim*self.original_dim*2))\n",
        "    pvar1 = self.pvar1(ez1.reshape(ez1.shape[0],self.original_dim*self.original_dim*2))\n",
        "\n",
        "    stdvar1 = pvar1.mul(0.5).exp_()\n",
        "\n",
        "    e1 = torch.randn([ez1.shape[0],self.original_dim*self.original_dim*2]).to(device)\n",
        "    e1 = pmu1 + e1*stdvar1\n",
        "    e1 = e1.reshape(e1.shape[0],8,self.original_dim//2,self.original_dim//2)\n",
        "    recons = nn.Sigmoid()(self.finconv(self.decblock3(self.usconv2(self.decblock2(torch.cat((ez1,e1),1))))))\n",
        "\n",
        "    return recons\n",
        "\n",
        "  def loss(self,x):\n",
        "    qmu0,qvar0,qmu1,qvar1,pmu1,pvar1,recons = self.forward(x)\n",
        "    klz0 = 0.5*torch.sum(torch.square(qmu0)+qvar0.exp()-qvar0-1)/x.shape[0]\n",
        "    klz1 = 0.5*torch.sum(torch.square(qmu1)/pvar1.exp()+qvar1.exp()-qvar1-1)\n",
        "    reconsloss = nn.BCELoss()(recons,x)\n",
        "    return klz0,klz1,reconsloss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "rV_UOrghS9D_"
      },
      "outputs": [],
      "source": [
        "batch_size=64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "_OEim05sTAJi"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "mRZ3zoLiTygD"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from PIL import Image\n",
        "\n",
        "class CocoDataloader(object):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.transform = transform\n",
        "        self.image_names = [os.path.join(data_dir, img) for img in listdir(data_dir) if os.path.join(data_dir, img)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        image = Image.open(self.image_names[idx])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, self.image_names[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "_dif2AmmTAf-"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train = CocoDataloader(FINAL_PATH, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "E3DuYQzHE5w_"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "vRr0LQ53U9jg"
      },
      "outputs": [],
      "source": [
        "model = NVAE(3,64).to(device)\n",
        "optim = torch.optim.Adamax(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "GI1pLbRBE9Hk"
      },
      "outputs": [],
      "source": [
        "epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vmJNzT2yU-4b",
        "outputId": "86beddf5-24bc-48d4-cdda-71e0e8c1d410"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    minloss = 1\n",
        "    running_kl0_loss=0\n",
        "    running_recons_loss=0\n",
        "    running_kl1_loss=0\n",
        "    num_images=0\n",
        "    for i, (img, image_name) in enumerate(loader):\n",
        "      img = img.to(device)\n",
        "      optim.zero_grad()\n",
        "      klz0,klz1,recons = model.loss(img)\n",
        "      loss=recons+epoch*0.001*klz0+epoch*0.001*klz1\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "      running_kl0_loss = running_kl0_loss + klz0.item()*len(img)\n",
        "      running_kl1_loss = running_kl1_loss + klz1.item()*len(img)\n",
        "      running_recons_loss = running_recons_loss + recons.item()*len(img)\n",
        "\n",
        "      num_images= num_images+len(img)\n",
        "    print('epoch: '+str(epoch)+' kl0_loss: '+str(running_kl0_loss/num_images)+' recons_loss: '+str(running_recons_loss/num_images)+' kl1_loss: '+str(running_kl1_loss/num_images))\n",
        "    img = model.sample(1).cpu().detach().reshape(64, 64, 3).numpy()\n",
        "    plt.imshow(img)\n",
        "    plt.savefig(str(epoch)+\".png\")\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NVAE_on_COCO(2).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
